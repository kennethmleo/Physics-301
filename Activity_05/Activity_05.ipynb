{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import thresholding as thresh\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_and_crop(event, x, y, flags, param):\n",
    "    global refPt, cropping\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        refPt = [(x, y)]\n",
    "        cropping = True\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        refPt.append((x, y))\n",
    "        cropping = False\n",
    "        cv2.rectangle(frame, refPt[0], refPt[1], (0, 0, 255), 2)\n",
    "        cv2.imshow(\"image\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "refPt = []\n",
    "cropping = False\n",
    "roi_exist = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", click_and_crop)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    width = int(cap.get(3))\n",
    "    height = int(cap.get(4))\n",
    "    if roi_exist == True:\n",
    "        image = np.zeros(frame.shape, np.uint8)\n",
    "        frame_ = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        roi_ = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        img_para = thresh.segment_parametric(frame_,roi_)\n",
    "        img_thresh = thresh.segment_thresholding(frame_,roi_)\n",
    "        \n",
    "        #denoising\n",
    "        #img_thresh = cv2.fastNlMeansDenoising(img_thresh, None, 10, 7, 21) \n",
    "        #img_para = cv2.fastNlMeansDenoising(img_para, None, 10, 7, 21)\n",
    "\n",
    "        #converting live-video feed to 4 parts\n",
    "        smaller_frame = cv2.resize(frame, (0,0), fx = 0.5, fy = 0.5)\n",
    "        smaller_para = cv2.resize(img_para, (0,0), fx = 0.5, fy = 0.5)\n",
    "        smaller_thresh = cv2.resize(img_thresh, (0,0), fx = 0.5, fy = 0.5)\n",
    "        smaller_still = cv2.resize(still, (0,0), fx = 0.5, fy = 0.5)\n",
    "        \n",
    "        image[:height//2, :width//2] = smaller_frame\n",
    "        image[height//2:, :width//2] = smaller_still\n",
    "        image[:height//2, width//2:] = np.stack((smaller_thresh, smaller_thresh, smaller_thresh), axis=2)\n",
    "        image[height//2:, width//2:] = np.stack((smaller_para, smaller_para, smaller_para), axis=2)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        image = cv2.putText(image, 'Thresholding', (width//2+10, height//2 - 10), font, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        image = cv2.putText(image, 'Parametric Segmentation', (width//2+10, height - 10), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"image\", image)\n",
    "    else:\n",
    "#         plt.imshow(frame)\n",
    "#         plt.show()\n",
    "        cv2.imshow(\"image\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if len(refPt) == 2 and roi_exist == False:\n",
    "        image = frame.copy()\n",
    "        still = frame.copy()\n",
    "        roi_exist = True\n",
    "        roi = image[refPt[0][1]:refPt[1][1], refPt[0][0]:refPt[1][0]]\n",
    "        #cv2.imshow(\"ROI\", roi)\n",
    "        cv2.imwrite('roi.png', roi)\n",
    "        #cv2.waitKey(1)\n",
    "    if key == ord(\"r\"):\n",
    "        refPt = []\n",
    "        roi_exist = False\n",
    "    elif key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "\n",
    "#cap = cv.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('traffic.mp4')\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100, qualityLevel = 0.3, minDistance = 7, blockSize = 7 )\n",
    "lk_params = dict( winSize  = (15, 15), maxLevel = 2, criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "mask = np.zeros_like(old_frame)\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "        frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "    img = cv.add(frame, mask)\n",
    "    cv.imshow('frame', img)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture('traffic.mp4')\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    cv.imshow('frame2', bgr)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv.imwrite('opticalfb.png', frame2)\n",
    "        cv.imwrite('opticalhsv.png', bgr)\n",
    "    prvs = next\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the cascade\n",
    "#face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# To capture video from webcam. \n",
    "cap = cv2.VideoCapture(0)\n",
    "# To use a video file as input \n",
    "# cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    # Display\n",
    "    cv2.imshow('img', img)\n",
    "    # Stop if escape key is pressed\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "# Release the VideoCapture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
